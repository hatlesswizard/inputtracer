package exploit

import (
	"testing"
)

func TestNewAssessor(t *testing.T) {
	a := NewAssessor()
	if a == nil {
		t.Fatal("expected non-nil Assessor")
	}

	stats := a.Stats()
	if stats["sanitizers"] == 0 {
		t.Error("expected default sanitizers to be registered")
	}
	if stats["dangerous_patterns"] == 0 {
		t.Error("expected default dangerous patterns to be registered")
	}
}

func TestAssessor_AssessDirectSQLi(t *testing.T) {
	a := NewAssessor()

	config := &AssessmentConfig{
		VulnType:   VulnTypeSQLi,
		SinkName:   "mysql_query",
		SourceName: "$_GET['id']",
		FilePath:   "test.php",
		Line:       10,
		TaintPath:  []string{"$_GET['id']", "$id", "mysql_query($sql)"},
		Conditions: []string{},
		Sanitizers: []string{},
		Context:    `$sql = "SELECT * FROM users WHERE id = " . $id;`,
	}

	assessment := a.Assess(config)

	if assessment.Level < LevelLikelyExploitable {
		t.Errorf("direct SQLi without sanitizer should be LikelyExploitable or higher, got %s",
			assessment.Level.String())
	}

	if assessment.HasSanitizer {
		t.Error("should not have sanitizer")
	}

	if len(assessment.PositiveFactors) == 0 {
		t.Error("expected positive factors (user-controlled source, string concat)")
	}

	if len(assessment.Recommendations) == 0 {
		t.Error("expected recommendations")
	}

	t.Logf("Assessment: Level=%s, Score=%.2f", assessment.Level.String(), assessment.Score)
	t.Logf("Positive factors: %d, Negative factors: %d",
		len(assessment.PositiveFactors), len(assessment.NegativeFactors))
}

func TestAssessor_AssessSanitizedSQLi(t *testing.T) {
	a := NewAssessor()

	config := &AssessmentConfig{
		VulnType:   VulnTypeSQLi,
		SinkName:   "mysql_query",
		SourceName: "$_GET['id']",
		FilePath:   "test.php",
		Line:       10,
		TaintPath:  []string{"$_GET['id']", "$id", "intval($id)", "mysql_query($sql)"},
		Sanitizers: []string{"intval"},
		Context:    `$id = intval($_GET['id']); $sql = "SELECT * FROM users WHERE id = " . $id;`,
	}

	assessment := a.Assess(config)

	if assessment.Level >= LevelLikelyExploitable {
		t.Errorf("SQLi with intval should be lower exploitability, got %s",
			assessment.Level.String())
	}

	if !assessment.HasSanitizer {
		t.Error("should have sanitizer flag set")
	}

	// Should have negative factor for sanitizer
	foundSanitizerFactor := false
	for _, f := range assessment.NegativeFactors {
		if f.Name == "effective_sanitizer" {
			foundSanitizerFactor = true
			break
		}
	}
	if !foundSanitizerFactor {
		t.Error("expected effective_sanitizer in negative factors")
	}

	t.Logf("Assessment with sanitizer: Level=%s, Score=%.2f", assessment.Level.String(), assessment.Score)
}

func TestAssessor_AssessXSS(t *testing.T) {
	a := NewAssessor()

	tests := []struct {
		name         string
		sanitizers   []string
		minLevel     ExploitabilityLevel
		maxLevel     ExploitabilityLevel
	}{
		{
			name:       "no_sanitizer",
			sanitizers: []string{},
			minLevel:   LevelLikelyExploitable,
			maxLevel:   LevelDefinitelyExploitable,
		},
		{
			name:       "htmlspecialchars",
			sanitizers: []string{"htmlspecialchars"},
			minLevel:   LevelNotExploitable,
			maxLevel:   LevelPossiblyExploitable, // Still possibly exploitable in some contexts
		},
		{
			name:       "strip_tags_only",
			sanitizers: []string{"strip_tags"},
			minLevel:   LevelPossiblyExploitable,
			maxLevel:   LevelLikelyExploitable,
		},
	}

	for _, tc := range tests {
		t.Run(tc.name, func(t *testing.T) {
			config := &AssessmentConfig{
				VulnType:   VulnTypeXSS,
				SinkName:   "echo",
				SourceName: "$_GET['name']",
				FilePath:   "test.php",
				Line:       5,
				TaintPath:  []string{"$_GET['name']", "echo"},
				Sanitizers: tc.sanitizers,
				Context:    `echo $name;`,
			}

			assessment := a.Assess(config)

			if assessment.Level < tc.minLevel || assessment.Level > tc.maxLevel {
				t.Errorf("expected level in [%s, %s], got %s",
					tc.minLevel.String(), tc.maxLevel.String(), assessment.Level.String())
			}

			t.Logf("%s: Level=%s, Score=%.2f", tc.name, assessment.Level.String(), assessment.Score)
		})
	}
}

func TestAssessor_AssessCommandInjection(t *testing.T) {
	a := NewAssessor()

	config := &AssessmentConfig{
		VulnType:   VulnTypeCommandInj,
		SinkName:   "exec",
		SourceName: "$_POST['cmd']",
		FilePath:   "test.php",
		Line:       15,
		TaintPath:  []string{"$_POST['cmd']", "exec($cmd)"},
		Conditions: []string{},
		Sanitizers: []string{},
		Context:    `exec("ls " . $cmd);`,
	}

	assessment := a.Assess(config)

	if assessment.Level < LevelLikelyExploitable {
		t.Errorf("command injection without sanitizer should be highly exploitable, got %s",
			assessment.Level.String())
	}

	t.Logf("Command injection: Level=%s, Score=%.2f", assessment.Level.String(), assessment.Score)
}

func TestAssessor_AssessWithAuthGuard(t *testing.T) {
	a := NewAssessor()

	config := &AssessmentConfig{
		VulnType:   VulnTypeSQLi,
		SinkName:   "mysql_query",
		SourceName: "$_GET['id']",
		FilePath:   "test.php",
		Line:       10,
		TaintPath:  []string{"$_GET['id']", "$id", "mysql_query($sql)"},
		Conditions: []string{"is_admin()", "is_logged_in()"},
		Sanitizers: []string{},
		Context:    `$sql = "SELECT * FROM users WHERE id = " . $id;`,
	}

	assessment := a.Assess(config)

	if !assessment.HasAuthGuard {
		t.Error("should detect auth guard from conditions")
	}

	// Auth guard should reduce exploitability somewhat
	// Score should be lower than direct exploitation
	if assessment.Score > 80 {
		t.Errorf("auth guard should reduce score, got %.2f", assessment.Score)
	}

	t.Logf("With auth guard: Level=%s, Score=%.2f", assessment.Level.String(), assessment.Score)
}

func TestAssessor_AssessWithTypeCoercion(t *testing.T) {
	a := NewAssessor()

	config := &AssessmentConfig{
		VulnType:   VulnTypeSQLi,
		SinkName:   "mysql_query",
		SourceName: "$_GET['id']",
		FilePath:   "test.php",
		Line:       10,
		TaintPath:  []string{"$_GET['id']", "(int)$_GET['id']", "$id", "mysql_query"},
		TypeCasts:  []string{"(int)"},
		Context:    `$id = (int)$_GET['id'];`,
	}

	assessment := a.Assess(config)

	if !assessment.HasTypeCoercion {
		t.Error("should detect type coercion")
	}

	// Type coercion to int should significantly reduce SQLi exploitability
	if assessment.Level > LevelPossiblyExploitable {
		t.Errorf("int cast should reduce SQLi exploitability, got %s", assessment.Level.String())
	}

	t.Logf("With type coercion: Level=%s, Score=%.2f", assessment.Level.String(), assessment.Score)
}

func TestAssessor_LongPath(t *testing.T) {
	a := NewAssessor()

	// Long taint path
	longPath := make([]string, 15)
	for i := range longPath {
		longPath[i] = "step" + string(rune('0'+i))
	}

	config := &AssessmentConfig{
		VulnType:   VulnTypeSQLi,
		SinkName:   "mysql_query",
		SourceName: "$_GET['id']",
		FilePath:   "test.php",
		Line:       100,
		TaintPath:  longPath,
		Context:    `mysql_query($sql);`,
	}

	assessment := a.Assess(config)

	// Long path should have negative factor
	foundLongPath := false
	for _, f := range assessment.NegativeFactors {
		if f.Name == "long_path" {
			foundLongPath = true
			break
		}
	}
	if !foundLongPath {
		t.Error("expected long_path in negative factors")
	}

	t.Logf("Long path: Level=%s, Score=%.2f, PathLength=%d",
		assessment.Level.String(), assessment.Score, assessment.PathLength)
}

func TestExploitabilityLevel_String(t *testing.T) {
	tests := []struct {
		level    ExploitabilityLevel
		expected string
	}{
		{LevelDefinitelyExploitable, "DEFINITELY_EXPLOITABLE"},
		{LevelLikelyExploitable, "LIKELY_EXPLOITABLE"},
		{LevelPossiblyExploitable, "POSSIBLY_EXPLOITABLE"},
		{LevelUnlikelyExploitable, "UNLIKELY_EXPLOITABLE"},
		{LevelNotExploitable, "NOT_EXPLOITABLE"},
		{LevelUnknown, "UNKNOWN"},
	}

	for _, tc := range tests {
		if tc.level.String() != tc.expected {
			t.Errorf("expected %s, got %s", tc.expected, tc.level.String())
		}
	}
}

func TestAssessor_AddSanitizer(t *testing.T) {
	a := NewAssessor()

	a.AddSanitizer(VulnTypeSQLi, "my_custom_escape", 0.95)

	config := &AssessmentConfig{
		VulnType:   VulnTypeSQLi,
		SinkName:   "mysql_query",
		SourceName: "$_GET['id']",
		TaintPath:  []string{"$_GET['id']", "$id", "mysql_query"},
		Sanitizers: []string{"my_custom_escape"},
	}

	assessment := a.Assess(config)

	if !assessment.HasSanitizer {
		t.Error("custom sanitizer should be detected")
	}

	t.Logf("With custom sanitizer: Level=%s, Score=%.2f", assessment.Level.String(), assessment.Score)
}

func TestAssessor_AddDangerousPattern(t *testing.T) {
	a := NewAssessor()

	err := a.AddDangerousPattern(VulnTypeSQLi, `CUSTOM_DANGER`)
	if err != nil {
		t.Fatalf("failed to add pattern: %v", err)
	}

	config := &AssessmentConfig{
		VulnType: VulnTypeSQLi,
		SinkName: "query",
		Context:  "CUSTOM_DANGER something",
	}

	assessment := a.Assess(config)

	foundPattern := false
	for _, f := range assessment.PositiveFactors {
		if f.Name == "dangerous_pattern" {
			foundPattern = true
			break
		}
	}
	if !foundPattern {
		t.Error("custom dangerous pattern should be detected")
	}
}

func TestAssessor_Stats(t *testing.T) {
	a := NewAssessor()

	stats := a.Stats()

	if stats["sanitizers"] == 0 {
		t.Error("expected sanitizers > 0")
	}
	if stats["dangerous_patterns"] == 0 {
		t.Error("expected dangerous_patterns > 0")
	}
	if stats["type_coercions"] == 0 {
		t.Error("expected type_coercions > 0")
	}

	t.Logf("Stats: %+v", stats)
}

func TestVulnerabilityTypes(t *testing.T) {
	types := []VulnerabilityType{
		VulnTypeSQLi,
		VulnTypeXSS,
		VulnTypeCommandInj,
		VulnTypePathTraversal,
		VulnTypeCodeExec,
		VulnTypeSSRF,
		VulnTypeDeserialization,
		VulnTypeXXE,
		VulnTypeOpenRedirect,
		VulnTypeUnknown,
	}

	for _, vt := range types {
		if string(vt) == "" {
			t.Error("vulnerability type should not be empty")
		}
	}
}

func TestClampScore(t *testing.T) {
	tests := []struct {
		input    float64
		expected float64
	}{
		{50, 50},
		{0, 0},
		{100, 100},
		{-10, 0},
		{150, 100},
		{99.5, 99.5},
	}

	for _, tc := range tests {
		result := clampScore(tc.input)
		if result != tc.expected {
			t.Errorf("clampScore(%f) = %f, expected %f", tc.input, result, tc.expected)
		}
	}
}
